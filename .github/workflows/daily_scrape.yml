name: Daily Product Scrape and Update
on:
  schedule:
    - cron: '0 20 * * *'
  workflow_dispatch:
    inputs:
      run_watsons:
        description: 'Run Watsons scraper'
        required: false
        type: boolean
        default: false
      run_poya:
        description: 'Run Poya scraper'
        required: false
        type: boolean
        default: false
      run_cosmed:
        description: 'Run Cosmed scraper'
        required: false
        type: boolean
        default: false
      run_all:
        description: 'Run all scrapers'
        required: false
        type: boolean
        default: true

jobs:
  scrape_watsons:
    if: ${{ github.event_name == 'schedule' || github.event.inputs.run_watsons == 'true' || github.event.inputs.run_all == 'true' }}
    runs-on: ubuntu-latest
    outputs:
      watsons_success: ${{ steps.scrape.outcome == 'success' }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          ref: master
      - name: Set up Python
        uses: actions/setup-python@v3
        with:
          python-version: '3.x'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install selenium webdriver-manager beautifulsoup4 requests tqdm
      - name: Run Watsons scraper
        id: scrape
        run: python scrape_watsons.py
        continue-on-error: true
      - name: Update scrape info and commit if successful
        if: ${{ steps.scrape.outcome == 'success' }}
        run: |
          python update_scrape_info.py watsons true 
          git config --local user.email "amyhsiao@gmail.com"
          git config --local user.name "amyhsiao"
          git add beauty4/scrape_info.json beauty4/watsons_*.json
          git commit -m "Daily scrape: Update Watsons product data and info" || echo "No Watsons changes to commit"
          git pull --rebase origin master
          git push origin master
        shell: bash

  scrape_poya:
    if: ${{ github.event_name == 'schedule' || github.event.inputs.run_poya == 'true' || github.event.inputs.run_all == 'true' }}
    runs-on: ubuntu-latest
    outputs:
      poya_success: ${{ steps.scrape.outcome == 'success' }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          ref: master
      - name: Set up Python
        uses: actions/setup-python@v3
        with:
          python-version: '3.x'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install selenium webdriver-manager beautifulsoup4 requests tqdm
      - name: Run Poya scraper
        id: scrape
        run: python scrape_poya.py
        continue-on-error: true
      - name: Update scrape info and commit if successful
        if: ${{ steps.scrape.outcome == 'success' }}
        run: |
          python update_scrape_info.py poya true 
          git config --local user.email "amyhsiao@gmail.com"
          git config --local user.name "amyhsiao"
          git add beauty4/scrape_info.json beauty4/poya_*.json
          git commit -m "Daily scrape: Update Poya product data and info" || echo "No Poya changes to commit"
          git pull --rebase origin master
          git push origin master
        shell: bash

  scrape_cosmed:
    if: ${{ github.event_name == 'schedule' || github.event.inputs.run_cosmed == 'true' || github.event.inputs.run_all == 'true' }}
    runs-on: ubuntu-latest
    outputs:
      cosmed_success: ${{ steps.scrape.outcome == 'success' }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          ref: master
      - name: Set up Python
        uses: actions/setup-python@v3
        with:
          python-version: '3.x'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install selenium webdriver-manager beautifulsoup4 requests tqdm
      - name: Run Cosmed scraper
        id: scrape
        run: python scrape_cosmed.py
        continue-on-error: true
      - name: Update scrape info and commit if successful
        if: ${{ steps.scrape.outcome == 'success' }}
        run: |
          python update_scrape_info.py cosmed true
          git config --local user.email "amyhsiao@gmail.com"
          git config --local user.name "amyhsiao"
          git add beauty4/scrape_info.json beauty4/cosmed_*.json
          git commit -m "Daily scrape: Update Cosmed product data and info" || echo "No Cosmed changes to commit"
          git pull --rebase origin master
          git push origin master
        shell: bash

  gather_update_status:
    needs: [scrape_watsons, scrape_poya, scrape_cosmed]
    runs-on: ubuntu-latest
    steps:
      - name: Check scrape status
        run: |
          echo "Watsons Scrape Status: ${{ needs.scrape_watsons.result }}, Poya Scrape Status: ${{ needs.scrape_poya.result }}, Cosmed Scrape Status: ${{ needs.scrape_cosmed.result }}"

  push_info_only:
    needs: gather_update_status
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          ref: master
      - name: Configure Git
        run: |
          git config --local user.email "amyhsiao@gmail.com"
          git config --local user.name "amyhsiao"
      - name: Commit and push scrape_info.json
        run: |
          git add beauty4/scrape_info.json
          git commit -m "Daily scrape: Update scrape_info.json" || echo "No scrape_info.json changes to commit"
          git pull --rebase origin master
          git push origin master
        shell: bash