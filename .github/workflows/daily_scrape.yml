name: Daily Product Scrape and Update
on:
  schedule:
    - cron: '0 20 * * *'
  workflow_dispatch:
    inputs:
      run_watsons:
        description: 'Run Watsons scraper'
        required: false
        type: boolean
        default: false
      run_poya:
        description: 'Run Poya scraper'
        required: false
        type: boolean
        default: false
      run_cosmed:
        description: 'Run Cosmed scraper'
        required: false
        type: boolean
        default: false
      run_all:
        description: 'Run all scrapers'
        required: false
        type: boolean
        default: true

jobs:
  scrape_watsons:
    if: ${{ github.event_name == 'schedule' || github.event.inputs.run_watsons == 'true' || github.event.inputs.run_all == 'true' }}
    runs-on: ubuntu-latest
    outputs:
      watsons_success: ${{ steps.scrape.outcome == 'success' }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          ref: master
      - name: Set up Python
        uses: actions/setup-python@v3
        with:
          python-version: '3.x'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install selenium webdriver-manager beautifulsoup4 requests tqdm
      - name: Run Watsons scraper
        id: scrape
        run: python scrape_watsons.py
        continue-on-error: true

  scrape_poya:
    if: ${{ github.event_name == 'schedule' || github.event.inputs.run_poya == 'true' || github.event.inputs.run_all == 'true' }}
    runs-on: ubuntu-latest
    outputs:
      poya_success: ${{ steps.scrape.outcome == 'success' }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          ref: master
      - name: Set up Python
        uses: actions/setup-python@v3
        with:
          python-version: '3.x'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install selenium webdriver-manager beautifulsoup4 requests tqdm
      - name: Run Poya scraper
        id: scrape
        run: python scrape_poya.py
        continue-on-error: true

  scrape_cosmed:
    if: ${{ github.event_name == 'schedule' || github.event.inputs.run_cosmed == 'true' || github.event.inputs.run_all == 'true' }}
    runs-on: ubuntu-latest
    outputs:
      cosmed_success: ${{ steps.scrape.outcome == 'success' }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          ref: master
      - name: Set up Python
        uses: actions/setup-python@v3
        with:
          python-version: '3.x'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install selenium webdriver-manager beautifulsoup4 requests tqdm
      - name: Run Cosmed scraper
        id: scrape
        run: python scrape_cosmed.py
        continue-on-error: true

  update_and_commit:
    needs: [scrape_watsons, scrape_poya, scrape_cosmed]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          ref: master
      - name: Set up Python
        uses: actions/setup-python@v3
        with:
          python-version: '3.x'
      - name: Update scrape info
        run: |
          # Update the scrape info based on which scrapers succeeded
          python update_scrape_info.py all ${{ needs.scrape_watsons.outputs.watsons_success == 'true' }} ${{ needs.scrape_poya.outputs.poya_success == 'true' }} ${{ needs.scrape_cosmed.outputs.cosmed_success == 'true' }}
      - name: Configure Git
        run: |
          git config --local user.email "amyhsiao@gmail.com"
          git config --local user.name "amyhsiao"
      - name: Commit and push changes
        run: |
          # Add all relevant files based on which scrapers succeeded
          git add beauty4/scrape_info.json
          
          if [ "${{ needs.scrape_watsons.outputs.watsons_success }}" == "true" ]; then
            git add beauty4/watsons_*.json
            echo "Adding Watsons data to commit"
          fi
          
          if [ "${{ needs.scrape_poya.outputs.poya_success }}" == "true" ]; then
            git add beauty4/poya_*.json
            echo "Adding Poya data to commit"
          fi
          
          if [ "${{ needs.scrape_cosmed.outputs.cosmed_success }}" == "true" ]; then
            git add beauty4/cosmed_*.json
            echo "Adding Cosmed data to commit"
          fi
          
          # Create commit message based on which scrapers succeeded
          COMMIT_MSG="Daily scrape:"
          if [ "${{ needs.scrape_watsons.outputs.watsons_success }}" == "true" ]; then
            COMMIT_MSG="$COMMIT_MSG Watsons,"
          fi
          if [ "${{ needs.scrape_poya.outputs.poya_success }}" == "true" ]; then
            COMMIT_MSG="$COMMIT_MSG Poya,"
          fi
          if [ "${{ needs.scrape_cosmed.outputs.cosmed_success }}" == "true" ]; then
            COMMIT_MSG="$COMMIT_MSG Cosmed,"
          fi
          COMMIT_MSG="${COMMIT_MSG%,} product data updated"
          
          # Commit and push with error handling
          git commit -m "$COMMIT_MSG" || echo "No changes to commit"
          git pull --rebase origin master
          git push origin master